<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Process Automation: An Update from the Trenches (Webinar Recording)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/d45lccoREB4/process-automation-an-update-from-the-trenches-webinar-recording.html" /><author><name>Kris Verlaenen</name></author><id>https://blog.kie.org/2021/09/process-automation-an-update-from-the-trenches-webinar-recording.html</id><updated>2021-09-29T09:31:50Z</updated><content type="html">Quick summary: Presentation and demo below ! &#x1f642; A few months ago, we did a set of webinars as part of our event, but for those that might have missed it, the recording is now available! In my session, I gave a bit of an introduction to Process Automation and our journey with jBPM. &gt; Automation has never been more important, but automating business processes &gt; end-to-end comes with many challenges.  Learn how Red Hat Process Automation &gt; Manager has evolved over the years to support the execution of complex &gt; processes at scale.  Hear about the building blocks we offer that make the &gt; life of developers easier and enable easy integration with many other &gt; technologies out there.  We will show you some of the latest improvements, &gt; from event-driven processes to a 100% cloud-native approach to bring your &gt; workloads to the hybrid cloud.  There’s also a live demo included (starting at 30:34). It’s showing an event-driven cloud-native straight-through process, with some focus on developer productivity in VSCode and scalability (buzzword bingo!). Enjoy! Feel free to also take a look at the sessions from Matteo on Decision Automation with DMN and from Geoffrey on vaccination scheduling with Optaplanner . The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/d45lccoREB4" height="1" width="1" alt=""/&gt;</content><dc:creator>Kris Verlaenen</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/process-automation-an-update-from-the-trenches-webinar-recording.html</feedburner:origLink></entry><entry><title type="html">Better reusability features on BPMN data types</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/BRIslPGQcCE/better-reusability-features-on-bpmn-data-types.html" /><author><name>Jaime Enriquez Parada</name></author><id>https://blog.kie.org/2021/09/better-reusability-features-on-bpmn-data-types.html</id><updated>2021-09-29T07:50:36Z</updated><content type="html">The latest addition to our Process Designer is a great feature that enhances the work with formulary data types. We added the ability to define the data type once and use it wherever the data type is needed to be used, as in Process Imports, Process Variables, Global Variables, DataObjects nodes, Multiple Instance Sub-processes and Data Assignments of activities Before this change, users needed to enter it manually in every place in the process designer. Now users can add it anywhere in the Process Designer. Once the data type is defined, if users  want to use it again, they can do so using the dropdowns of each Process Designer widget that allows selection of data type. Data types that are already existing in the process are also offered for selection when modelling or editing the process. For instance, let’s say you want a data object named DataObject of the type com.miType.DataObject, you would enter it as follows: Now, the data object’s data type is available to be selected in the Process Variables section. It will also be available in other places where users are able to select data type for variables, assignments etc. In process variables, you can use the dropdown list box widget to select the already defined Data Type In Global variables, you can use the dropdown list box widget to declare a default type, custom type, or already defined Data Type In Imports, you can use the dropdown list box widget to declare a default type, custom type, or already defined Data Type In Multiple Instances, you can use the dropdown list box widget to declare a default type, custom type, or already defined Data Type Data Assignments Input Data Assignments Output HOW THE SERVICE WORKS The service is composed of Server Side and Client Side components.  The server-side checks for any predefined Data Objects as Assets in the process while the client-side caches in all defined Data Types within the Diagram. In BC, both the server and the client-side work hand in hand, while the Kogito(VSCode extension) build has only the client-side. Regardless of Whether you use it in Business Central or VS Code extension, this feature will surely shorten your Diagram Design Time. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/BRIslPGQcCE" height="1" width="1" alt=""/&gt;</content><dc:creator>Jaime Enriquez Parada</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/better-reusability-features-on-bpmn-data-types.html</feedburner:origLink></entry><entry><title>Secure your Python applications with Thoth recommendations</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/KRxGzMs2cBg/secure-your-python-applications-thoth-recommendations" /><author><name>Fridolin Pokorny, Kevin Postlethwait</name></author><id>c7714d67-a94e-4bd3-9c04-d7f105baa955</id><updated>2021-09-29T07:00:00Z</updated><published>2021-09-29T07:00:00Z</published><summary type="html">&lt;p&gt;This article introduces you to using Thoth's security recommender to scan for flaws in your &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; applications. Security checks were recently added in &lt;a href="http://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt;, a &lt;a href="https://discuss.python.org/t/thoth-an-enhanced-server-side-resolution-offered-to-the-python-community/"&gt;cloud-based resolver for Python applications&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Why we need security recommendations&lt;/h2&gt; &lt;p&gt;Software engineering history has proven countless times that shipping secure software is not easy, and that security problems often lie not in the application developer's code but in imported packages. Software commonly uses libraries written by other developers, and an application's security is dependent on those libraries. If a library has vulnerabilities, the dependent application will inherit them when the library code is executed. Given the complexity and variety of libraries available in the open source world, it is not possible to review all the source code publicly available with rigorous security expertise.&lt;/p&gt; &lt;p&gt;Project Thoth is a native application on &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;, hosted on the &lt;a href="https://www.operate-first.cloud/"&gt;Operate First environment&lt;/a&gt;. Thoth can resolve software packages not to the “latest” but to the “greatest” library version. Thoth offers a variety of &lt;a href="https://thoth-station.ninja/recommendation-types/"&gt;recommendation types&lt;/a&gt; to determine the "greatest" version based on different criteria, which guides the installation process. Security is now one of Thoth's recommendation types.&lt;/p&gt; &lt;h2&gt;How Thoth makes security recommendations&lt;/h2&gt; &lt;p&gt;Thoth uses three main sources for security-based advisories that affect Python packages:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;The &lt;a href="https://github.com/pypa/advisory-db"&gt;Python Packaging Advisory Database&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Results computed in Thoth's "security indicators" workflow&lt;/li&gt; &lt;li&gt;&lt;a href="https://openssf.org/blog/2020/11/06/security-scorecards-for-open-source-projects/"&gt;Security scorecards for open source projects&lt;/a&gt; by the &lt;a href="https://openssf.org/"&gt;Open Source Security Foundation (OpenSSF)&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Recently, the &lt;a href="https://www.pypa.io/"&gt;Python Packaging Authority (PyPA)&lt;/a&gt; announced a publicly available database of known vulnerabilities in open source Python libraries, mostly those hosted on the &lt;a href="https://pypi.org/"&gt;Python Package Index (PyPI)&lt;/a&gt;. Thoth’s background data aggregation logic periodically fetches the database of known vulnerabilities and automatically blocks the resolution of &lt;a href="https://thoth-station.ninja/j/cve"&gt;software package versions that are prone to security vulnerabilities&lt;/a&gt;.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Watch &lt;a href="https://www.youtube.com/watch?v=R2i2lF4Ll4g"&gt;this video&lt;/a&gt; for a demonstration of how the resolver flags security problems.&lt;/p&gt; &lt;p&gt;Thoth engineers created the second source of data for security-based advisories. This source uses &lt;a href="https://developers.redhat.com/blog/2021/04/26/continuous-learning-in-project-thoth-using-kafka-and-argo"&gt;Thoth’s data aggregation architecture&lt;/a&gt;, in which each package imported by the application is statically scanned for possible issues using the open source &lt;a href="https://pypi.org/project/bandit/"&gt;Bandit&lt;/a&gt; tool. The information derived by Bandit is used to score packages during resolution. See &lt;a href="https://thoth-station.ninja/docs/developers/adviser/security.html"&gt;Thoth’s security advisories documentation&lt;/a&gt; for more about how Thoth uses Bandit.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;a href="https://www.youtube.com/watch?v=GypRonz01Hg"&gt;This video&lt;/a&gt; demonstrates how the Bandit-based recommendations are computed.&lt;/p&gt; &lt;p&gt;The third source of security-related advisories consists of security scorecards that provide health metrics for open-source software. See the &lt;a href="https://openssf.org/blog/2020/11/06/security-scorecards-for-open-source-projects/"&gt;OpenSSF blog&lt;/a&gt; or the &lt;a href="https://github.com/ossf/scorecard"&gt;OpenSSF GitHub repository&lt;/a&gt; for more about security scorecards.&lt;/p&gt; &lt;p&gt;Thoth’s resolution engine can easily be extended to include more sources of information. We are constantly looking for new sources and mechanisms for scoring packages. If you have domain knowledge in this area, the Thoth team welcomes your contributions and suggestions.&lt;/p&gt; &lt;h2&gt;Get a Thoth security recommendation&lt;/h2&gt; &lt;p&gt;To enable security-based recommendations that include the sources stated earlier, simply configure the recommendation type to be "security" in any of Thoth's three types of client tooling:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The &lt;a href="https://pypi.org/project/thamos/"&gt;Thamos&lt;/a&gt; command-line interface (CLI)&lt;/li&gt; &lt;li&gt;Thoth’s OpenShift &lt;a href="https://github.com/thoth-station/s2i-thoth/"&gt;Source-to-Image (S2I) container images&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://pypi.org/project/jupyterlab-requirements/"&gt;jupyterlab-requirements&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The easiest way to test security-based recommendations is to install the Thamos CLI, configure it, and ask Thoth for an advisory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ pip install thamos $ thamos config $ thamos add flask $ thamos advise --recommendation-type security&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this example, the cloud-based resolver evaluates versions of Flask as well as its dependencies. It will look for known security issues and suggest the most appropriate versions based on the most recent security knowledge for those dependencies. (See the end of this article for a video demonstration of the resolution process.)&lt;/p&gt; &lt;h2&gt;Using Thoth in the S2I build process&lt;/h2&gt; &lt;p&gt;The Thoth team provides container images that have Thoth tooling to consume recommendations during the OpenShift S2I build process. These container images are hosted on &lt;a href="https://quay.io/organization/thoth-station"&gt;Quay.io&lt;/a&gt; in the thoth-station organization. For the documentation, see the &lt;a href="https://github.com/thoth-station/s2i-thoth"&gt;GitHub repository&lt;/a&gt; hosting Thoth's S2I container images.&lt;/p&gt; &lt;p&gt;To benefit from Thoth’s recommendations in an OpenShift S2I process, use Thoth’s S2I base images during the build process. Because these images are compatible with vanilla S2I container images (in fact, the Thoth images are based on the vanilla ones), all you need to do is change the builder container image used in the S2I build process. The &lt;a href="https://pypi.org/project/thoth-s2i/"&gt;thoth-s2i&lt;/a&gt; tool can facilitate an automated transition to a Thoth-guided S2I build process.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: &lt;a href="https://www.youtube.com/watch?v=bOUEEh3u0Ug"&gt;This video&lt;/a&gt; shows the adjusted OpenShift S2I build process with Thoth advisories.&lt;/p&gt; &lt;h2&gt;Watch a video demonstration&lt;/h2&gt; &lt;p&gt;The following video gives an in-depth demonstration of how to resolve Python software packages without security vulnerabilities.&lt;/p&gt; &lt;p&gt;&lt;/p&gt; &lt;h2&gt;Helping the Python community create healthy applications&lt;/h2&gt; &lt;p&gt;As part of Project Thoth, we are accumulating knowledge about Python packages to help Python developers create healthy and secure applications. If you would like to follow updates in the project, please subscribe to the &lt;a href="https://www.youtube.com/channel/UClUIDuq_hQ6vlzmqM59B2Lw"&gt;Thoth Station YouTube channel&lt;/a&gt; or follow us on the &lt;a href="https://twitter.com/thothstation"&gt;@ThothStation Twitter handle&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/29/secure-your-python-applications-thoth-recommendations" title="Secure your Python applications with Thoth recommendations"&gt;Secure your Python applications with Thoth recommendations&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/KRxGzMs2cBg" height="1" width="1" alt=""/&gt;</summary><dc:creator>Fridolin Pokorny, Kevin Postlethwait</dc:creator><dc:date>2021-09-29T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/29/secure-your-python-applications-thoth-recommendations</feedburner:origLink></entry><entry><title type="html">Codeanywhere adventures - Getting started with browser based development in containers (part 1)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/N5F8i1B0ELc/codeanywhere-adventures-getting-started-browser-based-development-in-containers-part1.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/w_-D18LhPN8/codeanywhere-adventures-getting-started-browser-based-development-in-containers-part1.html</id><updated>2021-09-29T05:00:00Z</updated><content type="html">Are you ready for some amazing, easy to use, developer tooling that requires not a single tooling installation and no configuration?  That's what the team at are promising us with their cloud IDE when I stumbled on their website last week. They "...don't require you to engage in complex installations and configuration setups. Simply access our in-browser IDE for everything you need to build amazing websites in a productive and more developer-friendly way." Not only that, it's a browser-based developer IDE that ties your coding directly to a pipeline of deployment using containers with immediate friendly tips to access for testing your projects. I'm thinking we need to look at this a bit closer and wanted to share my adventures here with you, starting with part one, getting started. Full disclosure, I know some of the developers behind this product. Initially, I was using the free account they offer that you can spin from the button on the front page, but they reached out and gave me a bit more freedom to explore their offerings. Be sure to , they are a friendly bunch of developers and very happy to process any feedback you might have. HOW IT STARTED This adventure started as I was exploring a replacement for the docker tooling on my local machine, which led me to the tooling. A fine replacement, see my other articles on that exploration, but then I got to looking at how could we showcase our development projects and tooling using a browser only? Enter . Feel free to of this offering on their site, no need for me to determine for you if this is the right fit. I'm interested in Java development and wanted to test this out against one of my simple process automation tooling projects, could I get this into the IDE, build it, and deploy it in their container infrastructure within the bounds of my account? THE DASHBOARD I've chosen to use the Google Chrome browser for all the articles in this series, but it should not really matter so feel free to use your favourite browser. After logging in to the site, you can view. It presents the view to get started and reminds you that you have not yet created your first container. When you create a container you are then staring your first development project, that's end-to-end based on language type selection which will generate a project in your IDE and link that directly to a container to be deployed when you are ready. Before we do that, let's explore what else is available for our use. Under the menu on the right you can select SHARED WITH ME, to see a listing that is currently empty. If you have others you work with, here is where you can share container projects with other developers and you'll find them listed for your access. Pair programming of the future, at the container level! The CONNECTIONS item in the menu allows you to connect to SSH or FTP servers that might be hosing files, products, or projects that you want to be able to access from your IDE projects. Here is where you can add them to integrate them in the  IDE experience. ACCOUNT information includes the ability to connect to other developer services, view resource usage, and more. There is also the ability to create a TEAM ACCOUNT and put together your own CUSTOM STACKS for spinning up in a container where specific tooling versions might be required. Head back over to the CONTAINERS menu item and we'll get started in the next part of this series. So far you've taken a brief look at what this offering is, how to get it setup, and understand what you can do with it. Next up, part two takes us on a tour of setting up our very first container development project in the IDE.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/N5F8i1B0ELc" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/w_-D18LhPN8/codeanywhere-adventures-getting-started-browser-based-development-in-containers-part1.html</feedburner:origLink></entry><entry><title type="html">Introducing process operational monitoring for Kogito</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/TAhNJfc6NN8/introducing-process-operational-monitoring-for-kogito.html" /><author><name>Alessandro Costa</name></author><id>https://blog.kie.org/2021/09/introducing-process-operational-monitoring-for-kogito.html</id><updated>2021-09-28T10:00:00Z</updated><content type="html">Monitoring is a well known concept in Kogito: the was available since Kogito 0.11 through the Prometheus monitoring add-on. Today we announce that, starting from Kogito 1.11.0, this addon is enhanced to enable monitoring of processes. Unlike decisions, however, the feature is currently limited to operational metrics. The domain metrics section is a bit more complex to handle compared to decisions, so we decided to split the two and take some more time to properly design the latter while releasing the former to anyone who may benefit from it. KEY CONCEPTS The operational dashboard is intended to be used to check how your application responds quantitatively and to identify and react to possible malfunctions (e.g. slow responses, crash loops etc.). The addon currently exports one Grafana operational dashboard per process, which contains: * Total number of created instances * Total number of running instances * Total number of completed instances * Total number of instances that violated SLAs * Average process execution time, counted as the delta between the completion instant and the creation instant. There’s also a Global operational dashboard that contains the same graphs but with aggregated metrics for all the process types. You can use these default dashboards, or you can personalize them and use your custom dashboards. HOW TO USE IT First of all, the add-on must be imported in your Kogito project. The correct flavour (Quarkus or Spring Boot) must be chosen, depending on your underlying framework. Assuming that you have correctly imported the Kogito BOM to properly manage the versions, add the following dependency to your pom.xml: &lt;!-- Quarkus --&gt; &lt;dependency&gt; &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt; &lt;artifactId&gt;kogito-addons-quarkus-monitoring-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt; &lt;artifactId&gt;kogito-addons-springboot-monitoring-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; At this point, once the application is packaged with mvn clean package the dashboards are generated under the path target/generated-resources/kogito/dashboards and the DevOps engineer can easily inject them during the deployment of the Grafana container. For the Grafana provisioning, we suggest having a look at . Example of process operational dashboard EXAMPLES Complete examples are available for both and . Check them out and go through the READMEs to get your hands on the addon in the real world. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/TAhNJfc6NN8" height="1" width="1" alt=""/&gt;</content><dc:creator>Alessandro Costa</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/introducing-process-operational-monitoring-for-kogito.html</feedburner:origLink></entry><entry><title type="html">a KIE JBang! catalog</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/UWuhpX3Ns5E/a-kie-jbang-catalog.html" /><author><name>Matteo Mortari</name></author><id>https://blog.kie.org/2021/09/a-kie-jbang-catalog.html</id><updated>2021-09-28T09:53:34Z</updated><content type="html">In this episode, I want to share with you about an experimental catalog to quickly operate some KIE capabilities such as DMN and FEEL, directly on the Command Line! WHAT IS JBANG!? JBang! is a powerful command line and shell capability, allowing you to run jsh and Java source code as a script. JBang offers a great advantage with Java 8 compatibility and a very smart way to handle dependencies directly within the source of the scripts. You can read more about how JBang facilitates Developers, but also Students and Educators create, edit, and run self-contained source-only Java programs . You only need JBang to be installed on your system in order to follow the steps shown in the video and summarised in this post. DMN You can use the jbang dmn@kiegroup alias to evaluate a  using the Drools DMN Engine: The script takes as input a DMN mode file, and a DMN Context expressed as JSON. It produces as output a JSON of the evaluated DMN result context. As with most common command line utilities, you can issue --help to get usage help information: jbang dmn@kiegroup --help CONVERTER FOR EXCEL (.XLS/.XLSX) FILES CONTAINING DMN DECISION TABLES You can use the jbang xls2dmn@kiegroup alias to convert Excel (.xls/.xlsx) files containing  using the Drools DMN Engine experimental converter: For more details about the Converter and the conventions to be used in the Excel file, please reference the . FEEL You can use the jbang feel@kiegroup alias to evaluate a  using the Drools DMN Engine. This script takes as input a FEEL expression (as a string) and it produces a FEEL representation of the result of evaluating the expression. This jBang alias can be very handy when you want to quickly try out some FEEL expressions, using the command line for additional fun! CONCLUSIONS You can reference the video embedded with this post to get an overview of how to use this JBang! catalog. Don’t forget to checkout the for the full details. For more information on JBang, see: * * Try it out today! Go to: Don’t forget to let us know your feedback using the channels! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/UWuhpX3Ns5E" height="1" width="1" alt=""/&gt;</content><dc:creator>Matteo Mortari</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/a-kie-jbang-catalog.html</feedburner:origLink></entry><entry><title>Set up mod_cluster for Red Hat JBoss Web Server with Ansible</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qtlE4FYvRA8/set-modcluster-red-hat-jboss-web-server-ansible" /><author><name>Romain Pelisse</name></author><id>6b5869c5-b1df-4808-9163-01748ffb84ff</id><updated>2021-09-28T07:00:00Z</updated><published>2021-09-28T07:00:00Z</published><summary type="html">&lt;p&gt;In the article &lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible#"&gt;Automate Red Hat JBoss Web Server deployments with Ansible&lt;/a&gt;, we fully automated the setup of an &lt;a href="http://tomcat.apache.org/"&gt;Apache Tomcat server&lt;/a&gt; instance. In this follow-up, we'll further customize the behavior of the &lt;a href="https://developers.redhat.com/topics/enterprise-java/"&gt;Java&lt;/a&gt; web server. We will also use this opportunity to replace the Apache Tomcat distribution we deployed previously with &lt;a href="https://developers.redhat.com/products/webserver/overview"&gt;Red Hat JBoss Web Server&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Objectives&lt;/h2&gt; &lt;p&gt;We want to achieve two goals:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Replace Apache Tomcat with JBoss Web Server.&lt;/li&gt; &lt;li&gt;Activate the Java web server's &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_web_server/3/html/http_connectors_and_load_balancing_guide/sect-configure_load_balancing_using_apache_http_server_and_mod_cluster"&gt;&lt;code&gt;mod_cluster&lt;/code&gt; feature&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;As in the &lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible#"&gt;previous installment&lt;/a&gt;, we want to automate absolutely everything with &lt;a href="https://www.redhat.com/en/technologies/management/ansible"&gt;Ansible&lt;/a&gt;. This presents a slight challenge because we will have to retrieve the JBoss Web Server archive from the &lt;a href="https://access.redhat.com/"&gt;Red Hat Customer Portal&lt;/a&gt;—a protected resource.&lt;/p&gt; &lt;p&gt;As a reminder, our target environment is a &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux 8.4&lt;/a&gt; instance (so you can easily reproduce the demonstration):&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# cat /etc/redhat-release Red Hat Enterprise Linux release 8.4 (Ootpa) # ansible --version ansible 2.9.22 config file = /etc/ansible/ansible.cfg configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python3.6/site-packages/ansible executable location = /usr/bin/ansible python version = 3.6.8 (default, Mar 18 2021, 08:58:41) [GCC 8.4.1 20200928 (Red Hat 8.4.1-1)] &lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The playbook might not work if you want to use a different Python version or target operating system.&lt;/p&gt; &lt;p&gt;Before we start, let's recap where the &lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible#"&gt;previous article&lt;/a&gt; left off by examining the complete playbook we ended up with:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;--- - name: "JBoss Web Server installation and configuration" hosts: "all" become: yes collections: – middleware_automation.jws tasks : vars: tomcat_version: 9.0.50 tomcat_base_url: https://archive.apache.org/dist/tomcat/tomcat-9/v tomcat_download_url: "{{ tomcat_base_url }}{{ tomcat_version }}/bin/apache-tomcat-{{tomcat_version}}.zip" tomcat_install_dir: /opt tomcat_zipfile: "{{tomcat_install_dir}}/tomcat.zip" tomcat_java_version: 1.8.0 tomcat_setup: true collections: - middleware_automation.jws roles: - jws pre_tasks: - name: "Download latest Apache Tomcat Zipfile from {{ tomcat_download_url }}." get_url: url: "{{ tomcat_download_url }}" dest: "{{ tomcat_zipfile }}" when: - tomcat_download_url is defined tasks: - name: " Checks that server is running" uri: url: "http://localhost:8080/" status_code: 404 return_content: no - name: "Deploy demo webapp" get_url: url: 'https://people.redhat.com/~rpelisse/info-1.0.war' dest: "{{ tomcat_home }}/webapps/info.war" notify: - Restart Tomcat service post_tasks: - name: "Sleep for {{ tomcat_sleep }} seconds to let Tomcat starts " wait_for: timeout: "{{ tomcat_sleep }}" - name: "Test application" get_url: url: "http://localhost:8080/info/" dest: /tmp/info.txt&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;An important reminder: The installation of Apache Tomcat is not described in this playbook, as this is entirely managed by the &lt;a href="http://github.com/ansible-middleware/jws-ansible-playbook/"&gt;Ansible collection &lt;code&gt;middleware_automation.jws&lt;/code&gt;&lt;/a&gt;. We only need to provide the path to the Apache Tomcat ZIP file, and logic within the JBoss Web Server collection of Ansible will execute the installation from there.&lt;/p&gt; &lt;h2&gt;Install JBoss Web Server with Ansible&lt;/h2&gt; &lt;p&gt;The first change we need to make is to remove the Apache Tomcat distribution details, which means deleting (or commenting out) the following variables: &lt;code&gt;tomcat_version&lt;/code&gt;, &lt;code&gt;tomcat_base_url&lt;/code&gt;, and &lt;code&gt;tomcat_download_url&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;With that complete, we now have to define new variables that will provide the required values for the playbook to download and install JBoss Web Server:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; vars: … tomcat_install_method: rhn_zipfiles tomcat_zipfile: "{{ tomcat_install_dir }}/jws.zip" tomcat_home: "{{ tomcat_install_dir }}/jws-5.4/tomcat"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We also can remove the entire &lt;code&gt;pre_tasks&lt;/code&gt; section, as it was dedicated to the download of the Apache Tomcat archive that is no longer needed:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; pre_tasks: - name: "Download latest Apache Tomcat Zipfile from {{ tomcat_download_url }}." get_url: url: "{{ tomcat_download_url }}" dest: "{{ tomcat_zipfile }}" when: - tomcat_download_url is defined&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This new configuration will alter (at runtime) the behavior of the Ansible collection &lt;a href="http://github.com/ansible-middleware/jws-ansible-playbook/"&gt;&lt;code&gt;middleware_automation.jws&lt;/code&gt;&lt;/a&gt;. As you may recall from the &lt;a href="https://developers.redhat.com/articles/2021/08/30/automate-red-hat-jboss-web-server-deployments-ansible#"&gt;previous article&lt;/a&gt;, this collection has a dependency on another collection, &lt;a href="https://github.com/ansible-middleware/redhat-csp-download"&gt;&lt;code&gt;middleware_automation.redhat_csp_download&lt;/code&gt;&lt;/a&gt;, which—as the name suggests—downloads the required artifacts from the &lt;a href="https://access.redhat.com/"&gt;Red Hat Customer Portal&lt;/a&gt;. This dependency was not used in the previous article, but the changes to the variables will now activate it.&lt;/p&gt; &lt;p&gt;However, for this portion of the JBoss Web Server collection to run properly, we need to modify the playbook to reference the role name explicitly:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;collections: - middleware_automation.redhat_csp_download roles: - redhat_csp_download …&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To download the appropriate archive from the &lt;a href="https://access.redhat.com/"&gt;Red Hat customer portal&lt;/a&gt;, Ansible will need to authenticate, so we have to provide the proper credentials. We want to avoid specifying the connection details inside the main playbook, like other variables. So, we will use a separate file, called &lt;code&gt;credentials.yml&lt;/code&gt;, to specify them:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;--- rhn_username: username@redhat.com rhn_password: '&lt;password&gt;'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, we just need to have Ansible load those variables at execution time by specifying the file location as an additional variable:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ansible-playbook -i inventory -e @credentials.yml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that everything is in place, the next time Ansible runs, the execution will connect to the &lt;a href="https://access.redhat.com/"&gt;Red Hat customer portal&lt;/a&gt;, download the archive, and install JBoss Web Server.&lt;/p&gt; &lt;h2&gt;Activate mod_cluster&lt;/h2&gt; &lt;p&gt;One of the nice added values of the &lt;a href="http://github.com/ansible-middleware/jws-ansible-playbook/"&gt;Ansible collection &lt;code&gt;middleware_automation.jws&lt;/code&gt;&lt;/a&gt; is the support for setting up &lt;code&gt;mod_cluster&lt;/code&gt;, a rather advanced functionality of the Java web server. By specifying a few extra variables, Ansible can configure and activate this feature.&lt;/p&gt; &lt;p&gt;For those not familiar with &lt;code&gt;mod_cluster&lt;/code&gt;, let us briefly summarize the capability of this tool. &lt;a href="https://modcluster.io/"&gt;&lt;code&gt;mod_cluster&lt;/code&gt;&lt;/a&gt; is an intelligent load balancer that uses a communication channel to forward requests from the load balancer to one of a set of application server nodes. The beauty of this protocol is that most of the setup is fully dynamic. We just need to provide some basic information to JBoss Web Server for the server to connect to the httpd instance and register its services (deployed applications, address and port, etc.).&lt;/p&gt; &lt;p&gt;How can we achieve this? By adding just three variables to the playbook: The listening port for &lt;code&gt;modcluster&lt;/code&gt; (&lt;code&gt;6666&lt;/code&gt;), the IP address of the httpd server to connect to, and the listening port for the &lt;code&gt;modcluster&lt;/code&gt; service on the JBoss Web Server side. See the following code:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;vars : ... override_tomcat_modcluster_enable: yes override_tomcat_modcluster_ip: httpd.example.com override_tomcat_modcluster_port: 6666 override_tomcat_modcluster_listen_port: 6666&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Okay, we need a fourth variable to enable the feature within the collection, but that’s specific to the &lt;code&gt;automation_middleware.jws&lt;/code&gt; collection, not &lt;code&gt;mod_cluster&lt;/code&gt;.)&lt;/p&gt; &lt;p&gt;If we execute the playbook again, we can see that the &lt;code&gt;server.xml&lt;/code&gt; file is updated, which triggers a restart of the JBoss Web Server systemd service. This ensures the new settings are taken into account and activates the &lt;code&gt;mod_cluster&lt;/code&gt; functionality:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;... TASK [jws : Deploy custom configuration file from {{ item.template }}] *************************************************************************************** Friday 27 August 2021 05:53:26 -0400 (0:00:02.095) 0:00:38.688 ********* changed: [localhost] =&gt; (item={'template': 'templates/server.xml.j2', 'dest': '/opt/jws-5.4/tomcat/./conf/server.xml'}) ok: [localhost] =&gt; (item={'template': 'templates/web.xml.j2', 'dest': '/opt/jws-5.4/tomcat/./conf/web.xml'}) ok: [localhost] =&gt; (item={'template': 'templates/context.xml.j2', 'dest': '/opt/jws-5.4/tomcat/./conf/context.xml'}) TASK [jws : Remove app: {{ item }}] ************************************************************************************************************************** Friday 27 August 2021 05:53:28 -0400 (0:00:02.430) 0:00:41.118 ********* ok: [localhost] =&gt; (item=docs) ok: [localhost] =&gt; (item=ROOT) ok: [localhost] =&gt; (item=examples) TASK [jws : Copy tomcat vault file from control node to remote] ********************************************************************************************** Friday 27 August 2021 05:53:29 -0400 (0:00:01.142) 0:00:42.261 ********* skipping: [localhost] TASK [jws : Initialize tomcat vault] ************************************************************************************************************************* Friday 27 August 2021 05:53:30 -0400 (0:00:00.076) 0:00:42.337 ********* skipping: [localhost] RUNNING HANDLER [jws : Restart Tomcat service] *************************************************************************************************************** Friday 27 August 2021 05:53:30 -0400 (0:00:00.066) 0:00:42.404 ********* changed: [localhost] ... &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Customize the server.xml&lt;/h2&gt; &lt;p&gt;Quite often, the administrator of the JBoss Web Server (or Apache Tomcat) deployment will require fine-tuning of the &lt;code&gt;server.xml&lt;/code&gt; file. Up until this point, we have simply relied on the one generated automatically by the &lt;a href="http://github.com/ansible-middleware/jws-ansible-playbook/"&gt;Ansible collection &lt;code&gt;middleware_automation.jws&lt;/code&gt;&lt;/a&gt;. Indeed, it comes with its own templates that already allow transparent usage of a few complex features of the server (like &lt;code&gt;mod_cluster&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;While convenient, this approach cannot support all the possible configurations and implementation of the Java web server. This is why the collection also allows users to override the definition of this template in order to provide one of their own.&lt;/p&gt; &lt;p&gt;However, there is a (small) catch. If you have already activated some features (like &lt;code&gt;mod_cluster&lt;/code&gt;) with the help of the template supplied by the collection, those need to remain properly set up. It's easiest to use the &lt;code&gt;server.xml&lt;/code&gt; file from the collection as a base for the new template:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cp ~/.ansible/collections/ansible_collections/middleware_automation/jws/role/jws/templates/server.xml.j2 templates/server.xml.j2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With the custom template file in place, all that remains is to specify the &lt;code&gt;override_tomcat_conf_server&lt;/code&gt; variable so that the &lt;code&gt;automate_middleware.jws&lt;/code&gt; collection uses the new template file instead of the default:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;vars: … override_tomcat_conf_server: templates/server.xml.j2&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;That’s it! Just for the sake of completeness, the following is a bare-minimum template that you can use to build upon:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;Server port="{{ tomcat.shutdown.port }}" shutdown="SHUTDOWN"&gt; {% if tomcat.mod_cluster.enable %} &lt;Listener className="org.jboss.modcluster.container.catalina.standalone.ModClusterListener" connectorPort="{{ override_tomcat_modcluster_port }}" advertise="false" stickySession="true" stickySessionForce="false" stickySessionRemove="true" proxyList='{{ tomcat.mod_cluster.ip }}:{{ tomcat.mod_cluster.port }}'/&gt; {% endif %} &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector executor="tomcatThreadPool" port="{{ tomcat.listen.http.port }}" protocol="HTTP/1.1" allowTrace="false" {% if tomcat.listen.http.bind_address is defined %} address="{{ tomcat.listen.http.bind_address }}" {% endif %} connectionTimeout="20000" xpoweredBy="false" server="My Server" clientAuth="true" maxHttpHeaderSize="8192" redirectPort="{{ tomcat.listen.https.port }}"/&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt; &lt;/Server&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;As a brief recap, this article demonstrated how to:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Use JBoss Web Server instead of the Apache Tomcat distribution.&lt;/li&gt; &lt;li&gt;Activate its &lt;code&gt;mod_cluster&lt;/code&gt; features and customizing the &lt;code&gt;server.xml&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Fully automate deployment and configuration using Ansible.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;It's noteworthy that no extra Ansible tasks have been added to the playbook. All we had to do was modify a few configuration variables—the &lt;code&gt;middleware_automation.jws&lt;/code&gt; collection did all of the automation heavy lifting. Pretty neat, isn’t it?&lt;/p&gt; &lt;p&gt;Thanks to this JBoss Web Server Ansible collection, managing JBoss Web Server (or Apache Tomcat) within an Ansible playbook is as easy and lightweight as it is with other resources, such as Nginx or firewalld. In short, the Java web server is now a first-class citizen inside the Ansible ecosystem.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/28/set-modcluster-red-hat-jboss-web-server-ansible" title="Set up mod_cluster for Red Hat JBoss Web Server with Ansible"&gt;Set up mod_cluster for Red Hat JBoss Web Server with Ansible&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qtlE4FYvRA8" height="1" width="1" alt=""/&gt;</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2021-09-28T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/28/set-modcluster-red-hat-jboss-web-server-ansible</feedburner:origLink></entry><entry><title type="html">Developing business processes more efficiently with Runtime Tools Quarkus extension – Part 1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/fJvPMsppnLE/developing-business-processes-more-efficiently-with-runtime-tools-quarkus-extension-part-1.html" /><author><name>Paulo Martins</name></author><id>http://feeds.athico.com/~r/droolsatom/~3/fOftDz9KwZc/developing-business-processes-more-efficiently-with-runtime-tools-quarkus-extension-part-1.html</id><updated>2021-09-28T01:52:11Z</updated><content type="html">This the first of a series of posts presenting our new Runtime Tools Quarkus extension, which brings the main features of both Management and Task consoles to the development environment in a much easier way to set up. HISTORY In the past, to use features like process instances list, jobs management and task inbox locally, it was necessary to set up both Management and Task consoles. This requires a full environment filled with external services, similar to what you would need in production. In the first release of this extension, it still requires some services, but we are removing the need for them step by step, until the extension is able to run without depending on them. INSTALLATION To install the extension, you just need to add it as a dependency of your project: &lt;dependency&gt; &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt; &lt;artifactId&gt;runtime-tools-quarkus-extension&lt;/artifactId&gt; &lt;version&gt;1.11.0.Final&lt;/version&gt; &lt;/dependency&gt; And also add some properties to your project src/main/resources/application.properties file: # Data-index service URL org.kie.kogito.runtime.tools.quarkus.extension.runtime.dataindex.DataIndexClient/mp-rest/url=http://localhost:8180 # Mocked users and groups for the task inbox screen quarkus.kogito-runtime-tools.users=jdoe,admin,user quarkus.kogito-runtime-tools.users.jdoe.groups=admin quarkus.kogito-runtime-tools.users.admin.groups=admin quarkus.kogito-runtime-tools.users.user.groups=user As mentioned before, this release still needs a few external services to function properly: Data-index, Jobs service and Kafka. EXECUTION To try the extension out, we will use the in the repository. There you can also find a comprehensive README on how to run the example and run a process. The following steps will run all external services needed and also the consoles, if you want to try them out as well: 1. Clone repository git clone https://github.com/kiegroup/kogito-examples 2. Build the example cd process-usertasks-timer-quarkus-with-console mvn clean install -DskipTests 3. Run Docker images cd docker-compose ./startServices.sh 4. Start runtimes cd process-usertasks-timer-quarkus-with-console mvn clean compile quarkus:dev Once this is executed, you can access the Quarkus Dev UI in the browser: WALK-THROUGH Once you open de Quarkus Dev UI, you will see something like this: At the top-right corner, you can see the card of our extension, Kogito Runtime Tools. There you can check the counts for process instances, tasks and jobs, and also enter the extension by clicking in one of them: Now let’s start a new process instance by making the following request: curl -H "Content-Type: application/json" -H "Accept: application/json" -X POST http://localhost:8080/hiring -d @- &lt;&lt; EOF { "candidate": { "name": "Harry Potter", "email": "harrypotter@example.com", "salary": 30000, "skills": "Java, Kogito" } } EOF Now if we refresh the list we can see our new process instance: And if we click in the instance, we can see its details: As you can see in the diagram in the process details, this instance is currently waiting for the IT Interview user task to be completed. If we go to the tasks list using the left menu, we can see it: And when we click in its name, we can complete the task: Once the user task is completed, the process instance will finish, and you can verify that by going back to the process instance details screen. NEXT STEPS In the next releases, we are planning to add new features and capabilities that will improve the extension experience. Here are some of them: * Embedded in-memory data-index One of our goals is to remove all the need for external services when using the extension. The first of those will be the data-index. * Process list and start As you saw during the walk-through, a manual request was made to start a new process instance, because currently it is not possible to start them using the UI. We plan to add a process list screen, where it will be possible to see the processes available at runtime and start them, passing the needed information. * Custom task forms In our current distributions, user tasks forms are automatically generated based on its schema. With this feature, we plan to allow developers to make custom forms using React or HTML and use them instead of the generated ones. -------------------------------------------------------------------------------- Stay tuned, this is the first part of a series of posts that we will be making along with new releases of the extension. We hope these new features will help make the development of business processes easier and more powerful. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/fJvPMsppnLE" height="1" width="1" alt=""/&gt;</content><dc:creator>Paulo Martins</dc:creator><feedburner:origLink>http://feeds.athico.com/~r/droolsatom/~3/fOftDz9KwZc/developing-business-processes-more-efficiently-with-runtime-tools-quarkus-extension-part-1.html</feedburner:origLink></entry><entry><title type="html">Handling Effective Date and Expiry Date with DMN Decisions</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cICXoGpO-pA/handling-effective-date-and-expiry-date-with-dmn-decisions.html" /><author><name>Sadhana Nandakumar</name></author><id>https://blog.kie.org/2021/09/handling-effective-date-and-expiry-date-with-dmn-decisions.html</id><updated>2021-09-27T14:04:56Z</updated><content type="html">DMN is a modeling language and notation for the precise specification of business decisions. DMN is easily readable by the different types of people involved in decision management. supports the DMN open standards.  Handling effective date and expiry date of decisions is a common requirement across businesses. While it is entirely possible to handle the validity of decisions with different versions of the decision model, oftentimes there is a requirement to add variation at an individual decision node.  In this article, we will show how to achieve that with a practical example. Let us assume that we have a Card Approval Decision as shown below As you can see, we are calculating the Card Score based on Annual Income and Assets. This then determines if an Automatic Approval can be performed.  The Standard card score decision is expressed as a Decision Table: Let us say we now want a new condition for row 1, “When Annual Income &lt; 50 and Assets &lt; 100” starting with a specific date. Red Hat Process Automation Manager supports built-in functions to make this possible. today()Current Datenow()Current Date Time Let us now modify this decision table to add the date expiry condition. Notice how we have added the date condition to the decision row to decide it should be fired.  Let us now run these changes using the . The DMN artifact from this example is available .  Notice that since the effective date for Condition “When Annual Income &lt; 50 and Assets &lt; 100” matches the first row, the card Score evaluates to 312. Let us now change the rule to be effective from the beginning of this year and see what happens. You can now see that the rule matched the second row based on the date condition. Another way to define date validity is by defining it as a decision node so that one or more decisions can make use of it, it also allows you to make sure the logic is confined to one place. We will now use a combination of the built in date functions(today()/now()), as well as theto make this possible. Let us now create a new decision node called Date Validity.  Notice how we are using the temporal built-in function “after” in conjunction with “today” to determine validity. Now we will add this node to the existing DMN. The Standard card score now uses the Date Validity as defined by the decision node earlier. Let us now run this DMN. The DMN artifact from this example is available .  Since the effective date for the decision was next year, row 2 was fired yielding the card score result of 350. Test scenarios in Red Hat Process Automation Manager enable you to validate the functionality of business rules and business rule data before deploying them into a production environment. With a test scenario, you use data from your project to set given conditions and expected results based on one or more defined business rules. It is important to note that, while the test scenario by default maps the input data to the condition columns, it is possible to add a decision point as a condition column for better testability.  For instance, in the following scenario, you can see that Date Validity, which is a decision node in the DMN, is also pulled in as a condition column. If there needs to be a granular control of date checks, the decision node can be split up to reference date as an input column too. Now we can reference Today with different dates to test edge conditions seamlessly. References: – "Red Hat Decision Manager Supported Standards": * KIE Live 24: Squeezing the most out of DMN features, by . The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cICXoGpO-pA" height="1" width="1" alt=""/&gt;</content><dc:creator>Sadhana Nandakumar</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/handling-effective-date-and-expiry-date-with-dmn-decisions.html</feedburner:origLink></entry><entry><title>Four reasons developers should use Ansible</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gV-jNmtU-0Y/four-reasons-developers-should-use-ansible" /><author><name>Don Schenck</name></author><id>34c398d7-20c8-478f-b887-418e086e3d55</id><updated>2021-09-27T07:00:00Z</updated><published>2021-09-27T07:00:00Z</published><summary type="html">&lt;p&gt;Ansible is described as "simple IT automation." It's an agentless tool, meaning you don't have to install anything on the systems you are controlling. With Ansible, you can install software, configure system settings and features, and do all the things system administrators do. You know, the "operations" side of the team.&lt;/p&gt; &lt;p&gt;So why should you, a developer, care? You should. Let me explain.&lt;/p&gt; &lt;h2&gt;What does Ansible do?&lt;/h2&gt; &lt;p&gt;To put it in the simplest terms, Ansible lets you do things remotely that you would otherwise do at the command line. Specifically, it's used to install software and change system settings. It puts a machine into the state in which you want it to remain and keeps it there.&lt;/p&gt; &lt;p&gt;For example, you can install (and maintain) a given version of a library on a select group of servers across your organization. You might want &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; 3.8 on all your &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; machines running in AWS. Ansible is perfect for that.&lt;/p&gt; &lt;p&gt;Maybe you want to make sure version 2 of your own software is installed on those servers. Again, Ansible does that.&lt;/p&gt; &lt;p&gt;You can even do nifty things like perform a rolling update across your virtual machines (VMs). Remove some of the servers from the load balancer pool, update to version 3 of your software (using our example), and return the servers to the load balancer pool. Then move on to the next batch of servers, and so on, until all of your servers are running version 3 of your application.&lt;/p&gt; &lt;h2&gt;How Ansible can help developers&lt;/h2&gt; &lt;p&gt;Ansible is a big deal for developers because you can easily configure and maintain machines with what Ansible calls "playbooks": easy-to-read, declarative statements that you can store in source control. Take a look at this example (copied from the &lt;a href="https://www.ansible.com/blog/getting-started-writing-your-first-playbook"&gt;Ansible Getting Started page&lt;/a&gt;) and you'll be able to mostly figure out what it does:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;--- - name: Install nginx hosts: host.name.ip become: true tasks: - name: Add epel-release repo yum: name: epel-release state: present - name: Install nginx yum: name: nginx state: present - name: Insert Index Page template: src: index.html dest: /usr/share/nginx/html/index.html - name: Start NGiNX service: name: nginx state: started&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I can think of four reasons why you, as a developer, should care about Ansible:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;You can use it to set up small environments.&lt;/li&gt; &lt;li&gt;You can use it to make sure the correct prerequisites are installed.&lt;/li&gt; &lt;li&gt;You can be a catalyst for real DevOps culture at work.&lt;/li&gt; &lt;li&gt;You can use it for yourself.&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;1: You can use Ansible to set up small environments&lt;/h3&gt; &lt;p&gt;Throughout my many years in enterprise software development, my colleagues and I often had the opportunity to carve out small networks of our own. We used these networks to install various packages and software, test different approaches, try new things... in short, play around.&lt;/p&gt; &lt;p&gt;Having Ansible on hand to create environments quickly is fantastic. It's often desirable to set things up, experiment, then tear everything down and start over. Nothing is more frustrating than deploying a solution and having it fail with the "But it runs on our machines" experience, only because an artifact on your machine wasn't included in the installation process. Ansible can solve that by easily enabling you to start from zero every time.&lt;/p&gt; &lt;p&gt;As a developer, I love the idea of completely starting over every time—as long as it is super easy. Thanks, Ansible.&lt;/p&gt; &lt;h3&gt;2: You can use Ansible to make sure the correct prerequisites are installed&lt;/h3&gt; &lt;p&gt;Sometimes breaking changes to libraries or runtimes (Python, anyone?) can, well, break your application. Because Ansible playbooks are easy to understand and change—it's YAML, after all—you can enforce the correct version of any library, runtime, software, etc. This relieves operations from this burden, which plays perfectly into my next point.&lt;/p&gt; &lt;h3&gt;3: You can be a catalyst for real DevOps culture at work&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/devops/"&gt;DevOps&lt;/a&gt; is a culture and set of behaviors. It's not a spreadsheet or a piece of software you install. It's developers and operations working together to automate all the things. Having &lt;a href="https://www.redhat.com/en/topics/automation/what-is-infrastructure-as-code-iac"&gt;Infrastructure as Code&lt;/a&gt; is the basis. Allowing developers and operations to change that code, use version control, and trust one another—well, that's about as DevOps-y as you can get. The ability to pull down an Ansible playbook, run it, and test the results any time you want? That's huge. It is programming and system administration as one.&lt;/p&gt; &lt;h3&gt;4: You can use Ansible for yourself&lt;/h3&gt; &lt;p&gt;What if you were working on your laptop and you wanted to wipe it clean and start over? What if you could wipe it clean, pull a playbook from a network drive (or GitHub or a thumb drive or what-have-you), and use a tool to set up your machine?&lt;/p&gt; &lt;p&gt;With Ansible, you can do this over and over with the same results. You can repave your machine whenever you want without having to remember to run a script at the command line or install this and that.&lt;/p&gt; &lt;p&gt;In fact, as a developer, this might be your best use of Ansible and a great starting point for mastering it.&lt;/p&gt; &lt;h2&gt;Ops, I did it again&lt;/h2&gt; &lt;p&gt;So there it is. The old "DevOps" word again. We developers need to embrace it because it's not going away. Let's use this DevOps concept to everyone's advantage and promote cross-disciplinary skills, more Infrastructure as Code, and the ultimate goal: more stable systems. Something we all want.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/27/four-reasons-developers-should-use-ansible" title="Four reasons developers should use Ansible"&gt;Four reasons developers should use Ansible&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gV-jNmtU-0Y" height="1" width="1" alt=""/&gt;</summary><dc:creator>Don Schenck</dc:creator><dc:date>2021-09-27T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/27/four-reasons-developers-should-use-ansible</feedburner:origLink></entry></feed>
